import cv2
import numpy as np
import os
import glob
from tqdm import tqdm
import warnings
import time
warnings.filterwarnings('ignore')

class DepthEstimator:
    def __init__(self):
        """æ·±åº¦ä¼°è¨ˆå™¨"""
        self.current_image_name = ""
    
    def set_current_image(self, image_name):
        """è¨­ç½®ç•¶å‰è™•ç†çš„åœ–ç‰‡åç¨±"""
        self.current_image_name = image_name
    
    def adaptive_preprocessing(self, image):
        """è‡ªé©æ‡‰é è™•ç†"""
        with tqdm(total=4, desc=f"[{self.current_image_name}] è‡ªé©æ‡‰é è™•ç†", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            pbar.set_postfix_str("è½‰æ›ç°éš")
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            pbar.update(1)
            
            pbar.set_postfix_str("åˆ†æåœ–åƒç‰¹å¾µ")
            contrast = np.std(gray)
            brightness = np.mean(gray)
            pbar.update(1)
            
            pbar.set_postfix_str("é¸æ“‡è™•ç†ç­–ç•¥")
            if contrast < 30:  # ä½å°æ¯”åº¦
                pbar.set_postfix_str("ä½å°æ¯”åº¦å¢å¼·")
                enhanced = self.enhance_low_contrast(image)
            elif contrast > 80:  # é«˜å°æ¯”åº¦
                pbar.set_postfix_str("é«˜å°æ¯”åº¦å¹³æ»‘")
                enhanced = self.smooth_high_contrast(image)
            else:  # æ­£å¸¸å°æ¯”åº¦
                pbar.set_postfix_str("æ¨™æº–å¢å¼·")
                enhanced = self.standard_enhancement(image)
            pbar.update(1)
            
            pbar.set_postfix_str("å®Œæˆ")
            pbar.update(1)
        
        return enhanced
    
    def enhance_low_contrast(self, image):
        """ä½å°æ¯”åº¦åœ–åƒå¢å¼·"""
        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
        l_channel = lab[:,:,0]
        
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))
        l_channel = clahe.apply(l_channel)
        
        gamma = 0.8
        l_channel = np.power(l_channel/255.0, gamma) * 255
        l_channel = l_channel.astype(np.uint8)
        
        lab[:,:,0] = l_channel
        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        
        return enhanced
    
    def smooth_high_contrast(self, image):
        """é«˜å°æ¯”åº¦åœ–åƒå¹³æ»‘"""
        smoothed = cv2.bilateralFilter(image, 9, 75, 75)
        smoothed = cv2.GaussianBlur(smoothed, (3, 3), 0.5)
        return smoothed
    
    def standard_enhancement(self, image):
        """æ¨™æº–å¢å¼·è™•ç†"""
        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
        l_channel = lab[:,:,0]
        
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l_channel = clahe.apply(l_channel)
        
        lab[:,:,0] = l_channel
        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        
        return enhanced
    
    def multi_scale_texture_analysis(self, image):
        """å¤šå°ºåº¦ç´‹ç†åˆ†æ"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        texture_maps = []
        scales = [3, 7, 15, 25]
        
        with tqdm(total=len(scales), desc=f"[{self.current_image_name}] å¤šå°ºåº¦ç´‹ç†åˆ†æ", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            for scale in scales:
                pbar.set_postfix_str(f"è™•ç†å°ºåº¦ {scale}")
                
                gabor_responses = []
                angles = np.arange(0, 180, 30)
                frequency = 0.1 + 0.1 * (scale / 25)
                
                # å…§éƒ¨è§’åº¦è™•ç†é€²åº¦
                for angle in angles:
                    kernel = cv2.getGaborKernel(
                        (scale*2+1, scale*2+1), scale/3, np.radians(angle), 
                        2*np.pi*frequency, 0.5, 0, ktype=cv2.CV_32F
                    )
                    filtered = cv2.filter2D(gray, cv2.CV_32F, kernel)
                    gabor_responses.append(np.abs(filtered))
                
                scale_texture = np.mean(gabor_responses, axis=0)
                texture_maps.append(scale_texture)
                pbar.update(1)
        
        # åŠ æ¬Šèåˆ
        with tqdm(total=2, desc=f"[{self.current_image_name}] ç´‹ç†èåˆ", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            pbar.set_postfix_str("è¨ˆç®—åŠ æ¬Šèåˆ")
            weights = [0.4, 0.3, 0.2, 0.1]
            final_texture = np.zeros_like(texture_maps[0])
            
            for texture, weight in zip(texture_maps, weights):
                final_texture += texture * weight
            pbar.update(1)
            
            pbar.set_postfix_str("æ­£è¦åŒ–çµæœ")
            texture_depth = 255 - cv2.normalize(final_texture, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
            pbar.update(1)
        
        return texture_depth
    
    def improved_shadow_analysis(self, image):
        """æ”¹é€²çš„é™°å½±åˆ†æ"""
        with tqdm(total=6, desc=f"[{self.current_image_name}] é™°å½±åˆ†æ", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            pbar.set_postfix_str("è½‰æ›è‰²å½©ç©ºé–“")
            hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            pbar.update(1)
            
            pbar.set_postfix_str("HSVé™°å½±æª¢æ¸¬")
            h, s, v = cv2.split(hsv)
            shadow_hsv = (v < np.percentile(v, 25)) & (s < np.percentile(s, 40))
            pbar.update(1)
            
            pbar.set_postfix_str("LABé™°å½±æª¢æ¸¬")
            l, a, b = cv2.split(lab)
            shadow_lab = l < np.percentile(l, 20)
            pbar.update(1)
            
            pbar.set_postfix_str("çµåˆæª¢æ¸¬çµæœ")
            shadow_mask = shadow_hsv | shadow_lab
            pbar.update(1)
            
            pbar.set_postfix_str("å½¢æ…‹å­¸è™•ç†")
            kernel = np.ones((5,5), np.uint8)
            shadow_mask = cv2.morphologyEx(shadow_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)
            shadow_mask = cv2.morphologyEx(shadow_mask, cv2.MORPH_OPEN, kernel)
            pbar.update(1)
            
            pbar.set_postfix_str("è·é›¢è®Šæ›")
            shadow_distance = cv2.distanceTransform(
                (~shadow_mask.astype(bool)).astype(np.uint8), 
                cv2.DIST_L2, 5
            )
            
            shadow_depth = cv2.normalize(shadow_distance, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
            shadow_depth[shadow_mask.astype(bool)] = 200
            pbar.update(1)
        
        return shadow_depth
    
    def frequency_domain_analysis(self, image):
        """é »åŸŸåˆ†æ"""
        with tqdm(total=5, desc=f"[{self.current_image_name}] é »åŸŸåˆ†æ", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            pbar.set_postfix_str("è½‰æ›ç°éš")
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            pbar.update(1)
            
            pbar.set_postfix_str("FFTè®Šæ›")
            f_transform = np.fft.fft2(gray)
            f_shift = np.fft.fftshift(f_transform)
            pbar.update(1)
            
            pbar.set_postfix_str("å‰µå»ºé«˜é€šæ¿¾æ³¢å™¨")
            rows, cols = gray.shape
            crow, ccol = rows//2, cols//2
            
            mask = np.ones((rows, cols), np.uint8)
            r = 30
            center = [crow, ccol]
            x, y = np.ogrid[:rows, :cols]
            mask_area = (x - center[0])**2 + (y - center[1])**2 <= r*r
            mask[mask_area] = 0
            pbar.update(1)
            
            pbar.set_postfix_str("æ‡‰ç”¨æ¿¾æ³¢å™¨")
            f_shift_filtered = f_shift * mask
            pbar.update(1)
            
            pbar.set_postfix_str("åè®Šæ›å’Œæ­£è¦åŒ–")
            f_ishift = np.fft.ifftshift(f_shift_filtered)
            img_back = np.fft.ifft2(f_ishift)
            img_back = np.abs(img_back)
            
            frequency_depth = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
            pbar.update(1)
        
        return frequency_depth
    
    def gradient_coherence_analysis(self, image):
        """æ¢¯åº¦ä¸€è‡´æ€§åˆ†æ"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY).astype(np.float32)
        h, w = gray.shape
        
        with tqdm(total=4, desc=f"[{self.current_image_name}] æ¢¯åº¦åˆ†æ", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            pbar.set_postfix_str("è¨ˆç®—æ¢¯åº¦")
            grad_x = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
            
            magnitude = np.sqrt(grad_x**2 + grad_y**2)
            direction = np.arctan2(grad_y, grad_x)
            pbar.update(1)
            
            pbar.set_postfix_str("åˆå§‹åŒ–ä¸€è‡´æ€§åœ–")
            kernel_size = 15
            consistency_map = np.zeros_like(magnitude)
            pbar.update(1)
            
            pbar.set_postfix_str("è¨ˆç®—å±€éƒ¨ä¸€è‡´æ€§")
            total_pixels = (h - kernel_size) * (w - kernel_size)
            
            # ä½¿ç”¨å…§éƒ¨é€²åº¦æ¢é¡¯ç¤ºåƒç´ è™•ç†é€²åº¦
            pixel_pbar = tqdm(total=total_pixels, desc="      è™•ç†åƒç´ ", 
                            leave=False, ncols=80, ascii=True)
            
            for i in range(kernel_size//2, h - kernel_size//2):
                for j in range(kernel_size//2, w - kernel_size//2):
                    local_dir = direction[i-kernel_size//2:i+kernel_size//2+1, 
                                       j-kernel_size//2:j+kernel_size//2+1]
                    local_mag = magnitude[i-kernel_size//2:i+kernel_size//2+1, 
                                        j-kernel_size//2:j+kernel_size//2+1]
                    
                    if np.sum(local_mag) > 0:
                        weighted_cos = np.sum(local_mag * np.cos(local_dir - direction[i,j]))
                        weighted_sin = np.sum(local_mag * np.sin(local_dir - direction[i,j]))
                        coherence = np.sqrt(weighted_cos**2 + weighted_sin**2) / np.sum(local_mag)
                        consistency_map[i, j] = coherence
                    
                    pixel_pbar.update(1)
            
            pixel_pbar.close()
            pbar.update(1)
            
            pbar.set_postfix_str("æ­£è¦åŒ–çµæœ")
            coherence_depth = 255 - cv2.normalize(consistency_map, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
            pbar.update(1)
        
        return coherence_depth
    
    def advanced_edge_preserving_fusion(self, depth_maps, weights, reference_image):
        """é«˜ç´šé‚Šç·£ä¿æŒèåˆ"""
        with tqdm(total=4, desc=f"[{self.current_image_name}] é‚Šç·£ä¿æŒèåˆ", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            pbar.set_postfix_str("æª¢æ¸¬é‚Šç·£")
            gray = cv2.cvtColor(reference_image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 30, 100)
            edges = cv2.dilate(edges, np.ones((3,3)), iterations=1)
            pbar.update(1)
            
            pbar.set_postfix_str("è¨ˆç®—é‚Šç·£æ¬Šé‡")
            edge_weights = []
            for depth_map in depth_maps:
                grad_x = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
                grad_y = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
                depth_gradient = np.sqrt(grad_x**2 + grad_y**2)
                
                edge_reliability = depth_gradient * (edges / 255.0)
                edge_weights.append(edge_reliability)
            pbar.update(1)
            
            pbar.set_postfix_str("æ­£è¦åŒ–æ¬Šé‡")
            total_edge_weight = np.sum(edge_weights, axis=0)
            total_edge_weight[total_edge_weight == 0] = 1
            
            edge_weights = [ew / total_edge_weight for ew in edge_weights]
            pbar.update(1)
            
            pbar.set_postfix_str("èåˆæ·±åº¦åœ–")
            fused_depth = np.zeros_like(depth_maps[0], dtype=np.float32)
            
            for i, (depth_map, weight) in enumerate(zip(depth_maps, weights)):
                dynamic_weight = weight * 0.5 + edge_weights[i] * 0.5
                fused_depth += depth_map.astype(np.float32) * dynamic_weight
            pbar.update(1)
        
        return fused_depth.astype(np.uint8)
    
    def post_processing_pipeline(self, depth_map, reference_image):
        """å¾Œè™•ç†ç®¡é“"""
        with tqdm(total=4, desc=f"[{self.current_image_name}] å¾Œè™•ç†", 
                 leave=False, ncols=100, ascii=True) as pbar:
            
            pbar.set_postfix_str("é›™é‚Šæ¿¾æ³¢å»å™ª")
            denoised = cv2.bilateralFilter(depth_map, 9, 75, 75)
            pbar.update(1)
            
            pbar.set_postfix_str("é‚Šç·£æª¢æ¸¬")
            gray = cv2.cvtColor(reference_image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            edge_mask = edges / 255.0
            pbar.update(1)
            
            pbar.set_postfix_str("é‚Šç·£å¢å¼·")
            enhanced = denoised * (1 - edge_mask) + depth_map * edge_mask
            pbar.update(1)
            
            pbar.set_postfix_str("æœ€çµ‚å¹³æ»‘")
            smoothed = cv2.GaussianBlur(enhanced.astype(np.uint8), (3, 3), 0.5)
            final = enhanced * edge_mask + smoothed * (1 - edge_mask)
            pbar.update(1)
        
        return final.astype(np.uint8)
    
    def estimate_depth(self, image_rgb):
        """å°å–®å¼µåœ–ç‰‡é€²è¡Œæ·±åº¦ä¼°è¨ˆ"""
        print(f"/nğŸ” é–‹å§‹è™•ç†: {self.current_image_name}")
        
        # ç¸½é€²åº¦è¿½è¹¤
        with tqdm(total=6, desc=f"[{self.current_image_name}] ç¸½é«”é€²åº¦", 
                 position=0, leave=True, ncols=120, ascii=True) as main_pbar:
            
            # 1. è‡ªé©æ‡‰é è™•ç†
            main_pbar.set_postfix_str("è‡ªé©æ‡‰é è™•ç†")
            enhanced_image = self.adaptive_preprocessing(image_rgb)
            main_pbar.update(1)
            
            # 2. å¤šå°ºåº¦ç´‹ç†åˆ†æ
            main_pbar.set_postfix_str("å¤šå°ºåº¦ç´‹ç†åˆ†æ")
            texture_depth = self.multi_scale_texture_analysis(enhanced_image)
            main_pbar.update(1)
            
            # 3. é™°å½±åˆ†æ
            main_pbar.set_postfix_str("é™°å½±åˆ†æ")
            shadow_depth = self.improved_shadow_analysis(enhanced_image)
            main_pbar.update(1)
            
            # 4. é »åŸŸåˆ†æ
            main_pbar.set_postfix_str("é »åŸŸåˆ†æ")
            frequency_depth = self.frequency_domain_analysis(enhanced_image)
            main_pbar.update(1)
            
            # 5. æ¢¯åº¦ä¸€è‡´æ€§åˆ†æ
            main_pbar.set_postfix_str("æ¢¯åº¦ä¸€è‡´æ€§åˆ†æ")
            coherence_depth = self.gradient_coherence_analysis(enhanced_image)
            main_pbar.update(1)
            
            # 6. èåˆå’Œå¾Œè™•ç†
            main_pbar.set_postfix_str("èåˆå’Œå¾Œè™•ç†")
            depth_maps = [texture_depth, shadow_depth, frequency_depth, coherence_depth]
            weights = [0.35, 0.25, 0.25, 0.15]
            
            fused_depth = self.advanced_edge_preserving_fusion(depth_maps, weights, enhanced_image)
            final_depth = self.post_processing_pipeline(fused_depth, enhanced_image)
            main_pbar.update(1)
            
            main_pbar.set_postfix_str("å®Œæˆ")
        
        return final_depth

def process_folder(input_folder, output_folder):
    """æ‰¹æ¬¡è™•ç†è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰åœ–ç‰‡"""
    
    # å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾
    os.makedirs(output_folder, exist_ok=True)
    
    # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']
    
    # æ”¶é›†æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆï¼ˆé¿å…é‡è¤‡ï¼‰
    image_files = set()  # ä½¿ç”¨seté¿å…é‡è¤‡
    for extension in image_extensions:
        image_files.update(glob.glob(os.path.join(input_folder, extension)))
        image_files.update(glob.glob(os.path.join(input_folder, extension.upper())))
    
    image_files = sorted(list(image_files))  # è½‰å›listä¸¦æ’åº
    
    if not image_files:
        print(f"âŒ åœ¨è³‡æ–™å¤¾ {input_folder} ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡æª”æ¡ˆ")
        return
    
    print("="*80)
    print(f"ğŸš€ é–‹å§‹æ‰¹æ¬¡æ·±åº¦ä¼°è¨ˆè™•ç†")
    print("="*80)
    print(f"ğŸ“ è¼¸å…¥è³‡æ–™å¤¾: {input_folder}")
    print(f"ğŸ“¤ è¼¸å‡ºè³‡æ–™å¤¾: {output_folder}")
    print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} å¼µåœ–ç‰‡")
    print("="*80)
    
    # åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨
    estimator = DepthEstimator()
    
    successful = 0
    failed = 0
    start_time = time.time()
    
    # è™•ç†æ¯å¼µåœ–ç‰‡
    for i, image_path in enumerate(image_files, 1):
        try:
            filename = os.path.basename(image_path)
            print(f"/nğŸ“· [{i}/{len(image_files)}] {filename}")
            
            # è¨­ç½®ç•¶å‰è™•ç†çš„åœ–ç‰‡åç¨±
            estimator.set_current_image(filename)
            
            # è®€å–åœ–ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                print(f"âŒ ç„¡æ³•è®€å–: {image_path}")
                failed += 1
                continue
            
            # è½‰æ›ç‚ºRGBæ ¼å¼
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # é€²è¡Œæ·±åº¦ä¼°è¨ˆ
            depth_map = estimator.estimate_depth(image_rgb)
            
            # ç”Ÿæˆè¼¸å‡ºæª”åï¼ˆä¿æŒåŸå§‹æª”åï¼‰
            name, ext = os.path.splitext(filename)
            output_path = os.path.join(output_folder, f"{name}_depth{ext}")
            
            # ä¿å­˜æ·±åº¦åœ–
            cv2.imwrite(output_path, depth_map)
            successful += 1
            
            print(f"âœ… å®Œæˆ: {filename} â†’ {name}_depth{ext}")
            
            # è¨ˆç®—é ä¼°å‰©é¤˜æ™‚é–“
            elapsed_time = time.time() - start_time
            if i > 0:
                avg_time_per_image = elapsed_time / i
                remaining_images = len(image_files) - i
                eta = avg_time_per_image * remaining_images
                eta_str = f"{eta//60:.0f}åˆ†{eta%60:.0f}ç§’" if eta >= 60 else f"{eta:.0f}ç§’"
                print(f"â±ï¸  é ä¼°å‰©é¤˜æ™‚é–“: {eta_str}")
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•— {filename}: {e}")
            failed += 1
    
    # å®Œæˆå ±å‘Š
    total_time = time.time() - start_time
    total_time_str = f"{total_time//60:.0f}åˆ†{total_time%60:.0f}ç§’" if total_time >= 60 else f"{total_time:.0f}ç§’"
    
    print("/n" + "="*80)
    print(f"ğŸ‰ æ‰¹æ¬¡è™•ç†å®Œæˆï¼")
    print("="*80)
    print(f"â±ï¸  ç¸½è™•ç†æ™‚é–“: {total_time_str}")
    print(f"âœ… æˆåŠŸè™•ç†: {successful} å¼µ")
    print(f"âŒ è™•ç†å¤±æ•—: {failed} å¼µ")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {(successful/(successful+failed)*100):.1f}%" if (successful+failed) > 0 else "0%")
    print(f"ğŸ“ çµæœä¿å­˜åœ¨: {output_folder}")
    print("="*80)

def main():
    """ä¸»å‡½æ•¸"""
    # è¨­å®šè¼¸å…¥å’Œè¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘
    input_folder = r"AerialImageDataset\train\images"      # ä¿®æ”¹ç‚ºä½ çš„è¼¸å…¥è³‡æ–™å¤¾
    output_folder = r"depth/output"     # ä¿®æ”¹ç‚ºä½ çš„è¼¸å‡ºè³‡æ–™å¤¾
    
    # æª¢æŸ¥è¼¸å…¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_folder):
        print(f"âŒ è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {input_folder}")
        print("è«‹ä¿®æ”¹ input_folder è·¯å¾‘ç‚ºä½ çš„å¯¦éš›åœ–ç‰‡è³‡æ–™å¤¾")
        return
    
    # é–‹å§‹æ‰¹æ¬¡è™•ç†
    process_folder(input_folder, output_folder)

if __name__ == "__main__":
    main()